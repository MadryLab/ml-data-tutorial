{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Linear Datamodeling Score (LDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to walk through the steps of computing the Linear Datamodeling Score (LDS) for a small neural network trained on a subset of the CIFAR-10 dataset containing 5,000 samples. For more details on the LDS, please check out Section 2 in https://arxiv.org/abs/2303.14186."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1481195/4064116203.py:3: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils import train_on_subset, record_outputs, get_loader\n",
    "np.random.seed(42)  # fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a few subsets of the training set $\\{S_1, S_2, ..., S_n\\}$.\n",
    "In general, we can construct these subsets in any way we desire.\n",
    "Here, we are going to pick random halves of the training set. In particular, since our subset of the CIFAR-10 has 5,000 training samples, for each $S_i$ we are going to sample 2,500 i.i.d. samples from it without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create 20 random subsets of the training set\n",
    "#    (each containing a half of the samples)\n",
    "train_set_subsets = []\n",
    "for i in range(20):\n",
    "    subset = np.random.choice(range(5_000), 2_500, replace=False)\n",
    "    train_set_subsets.append(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to obtain \"ground truth\" outputs for each subset. In particular, we are going to train a model on each subset $S_i$ and record its output on a few target examples of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. train a model on each subset\n",
    "#    and record its output on a target example of choice\n",
    "\n",
    "val_loader = get_loader(split=\"val\")\n",
    "# let's use the first batch of validation data as our target examples\n",
    "target_examples = next(iter(val_loader))\n",
    "\n",
    "outputs_per_subset = []\n",
    "for subset in tqdm(train_set_subsets):\n",
    "    # we have abstracted away the \"boring\" parts of the code in utils.py\n",
    "    model = train_on_subset(subset)\n",
    "    # our model outputs are the margins of the model on the target examples\n",
    "    # i.e., the difference between the model's logit on the correct class and\n",
    "    # the log-sum-exp (think of that as a soft maximum) of logits on the incorrect classes\n",
    "    outs = record_outputs(model, target_examples)\n",
    "    outputs_per_subset.append(outs)\n",
    "\n",
    "outputs_per_subset = torch.stack(outputs_per_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you don't want to train the above models yourself, we have provided precomputed model outputs below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (pre-computed version)\n",
    "\n",
    "outputs_per_subset = torch.load('artifacts/lds_outputs_per_subset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load in the scores from our predictive data attribution method of choice! For now, let's just use random scores as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. get predicted model outputs from your attribution method for each subset;\n",
    "#    here's where linearity comes into play, our prediction is the sum of\n",
    "#    attribution scores across samples within the subset\n",
    "\n",
    "# dummy scores; try to replace with your own, e.g., from the TRAK or IFs notebooks :)\n",
    "dummy_attribution_scores = torch.randn(5_000, 256)  # 256 is the number of target examples\n",
    "\n",
    "predictions_per_subset = []\n",
    "for subset in train_set_subsets:\n",
    "    prediction = dummy_attribution_scores[subset].sum(dim=0)\n",
    "    predictions_per_subset.append(prediction)\n",
    "predictions_per_subset = torch.stack(predictions_per_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the rank-correlation between the true model outputs and the predictions from our attribution method. In essence, we are asking how good our attribution method is at discerning which subsets $S_i$ will lead to a higher / lower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDS: 0.011\n"
     ]
    }
   ],
   "source": [
    "# 4. evaluate the rank-correlation between the true model outputs\n",
    "#    and the predictions from our attribution method\n",
    "from scipy.stats import spearmanr\n",
    "LDS = 0.\n",
    "pval = 0.\n",
    "for i in range(outputs_per_subset.shape[1]): # iterate over target examples\n",
    "    LDS += spearmanr(outputs_per_subset[:, i], predictions_per_subset[:, i]).correlation\n",
    "\n",
    "LDS = LDS / outputs_per_subset.shape[1]\n",
    "print(f'LDS: {LDS:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, given that we loaded random scores as a placeholder, the LDS is close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we would evaluate the correlations for many target examples,\n",
    "and then average the correlations across the target examples. The code below implements the many-target version of LDS efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import wget\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_correlations(scores, tmp_path):\n",
    "    masks_url = 'https://www.dropbox.com/s/x76uyen8ffkjfke/mask.npy?dl=1'\n",
    "    margins_url = 'https://www.dropbox.com/s/q1dxoxw78ct7c27/val_margins.npy?dl=1'\n",
    "\n",
    "    masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "    wget.download(masks_url, out=str(masks_path), bar=None)\n",
    "    # num masks, num train samples\n",
    "    masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "\n",
    "    margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "    wget.download(margins_url, out=str(margins_path), bar=None)\n",
    "    # num , num val samples\n",
    "    margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "\n",
    "    val_inds = np.arange(2_000)\n",
    "    preds = masks @ scores\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind, j in tqdm(enumerate(val_inds)):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, j])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "    return rs.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
